{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Creating Data for Final Annotation\n",
    "Harvesting, transforming, and exporting metadata descriptions for annotation of gendered language in [brat](brat.nlplab.org/).\n",
    "\n",
    "The text in this Jupyter Notebook is organized for uploading into [brat](https://brat.nlplab.org/index.html), where the text will be annotated for instances of gender bias.  The aim of the annotation is to create a gold standard dataset on which a classifier can be trained to identify gender bias in archival metadata descriptions.  \n",
    "\n",
    "This project is focused on the English language and archival institutions in the United Kingdom.\n",
    "\n",
    "* Creator: Lucy Havens\n",
    "* Date: February 2021 - April 2021\n",
    "* Project: PhD research at the School of Informatics, University of Edinburgh\n",
    "* Data Source: Centre for Research Collections' (CRC) [online archival catalog](https://archives.collections.ed.ac.uk/)\n",
    "\n",
    "***\n",
    "**Table of Contents**\n",
    "\n",
    "  [I. Harvesting](#harvesting)\n",
    "\n",
    "  [II. Transforming](#transforming)\n",
    "\n",
    "  [III. Preparing](#preparing)\n",
    "\n",
    "  [IV. Renaming Pre-annotated Files](#renaming)\n",
    "  \n",
    "  [V. Splitting Files Among Annotators](#splitting)\n",
    "  \n",
    "  ***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"harvesting\"></a>\n",
    "## I. Harvesting\n",
    "Obtain metadata from the CRC's online archival catalog using the Open Archives Initiative - Protocol for Metadata Harvesting (OAI-PMH).  The CRC provides its metadata in Encoded Archival Description (EAD) format as XML data.  Harvest metadata descriptions from the following metadata fields in the Centre for Research Collections' online catalog:\n",
    "  * Scope and Contents\n",
    "  * Biographical Historical\n",
    "  * Processing Information\n",
    "  * Title\n",
    "  * Language of Material\n",
    "  * Geography Name\n",
    "  * Unit ID\n",
    "  * Encoded Archival Description Identifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import libraries for harvesting\n",
    "import xml.dom.minidom\n",
    "import urllib.request\n",
    "import urllib\n",
    "import xml.etree.ElementTree as ET\n",
    "from lxml import etree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<Element {http://www.openarchives.org/OAI/2.0/}OAI-PMH at 0x7fc04a4950c0>\n"
     ]
    }
   ],
   "source": [
    "archiveMetadataUrl = \"http://lac-archives-live.is.ed.ac.uk:8082/?verb=ListRecords&metadataPrefix=oai_ead\"\n",
    "\n",
    "def getRootFromUrl(url):\n",
    "    content = urllib.request.urlopen(url)\n",
    "\n",
    "    #tree = ET.parse(content)\n",
    "    parser = etree.XMLParser(recover=True)  # Use recover to try to fix broken XML\n",
    "    tree = etree.parse(content, parser)\n",
    "    \n",
    "    root = tree.getroot()\n",
    "    return root\n",
    "\n",
    "root = getRootFromUrl(archiveMetadataUrl)\n",
    "print(root)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Input: part of or the entirety of a tag name below which you want to get text \n",
    "# Output: a list of text between tags contained within the inputted tagName, \n",
    "#         with one list element per tagName instance\n",
    "def getTextBeneathTag(root, tagName, header):\n",
    "    text_list = []\n",
    "    for child in root.iter():\n",
    "        tag = child.tag\n",
    "        if tagName in tag:\n",
    "            text_elem = \"\"\n",
    "            for subchild_text in child.itertext():\n",
    "                if header:\n",
    "                    if header not in subchild_text:\n",
    "                        text_elem = text_elem + subchild_text\n",
    "                else:\n",
    "                    text_elem = text_elem + subchild_text\n",
    "            text_list.append(text_elem)\n",
    "    return text_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Input: binary value, url for harvesting metadata, starting prefix for the end of the url, and lists of metadata fields to gather\n",
    "# Output: lists of strings of the gathered metadata fields' descriptions, with one string per fonds, series, and item in the catalog\n",
    "def getDescriptiveMetadata(more, archiveMetadataUrlShort, startingPrefix, eadid, ut, ui, ud, gn, lm, sc, bh, pi):    \n",
    "   \n",
    "    archiveMetadataUrlWithPrefix = archiveMetadataUrlShort + startingPrefix\n",
    "    root = getRootFromUrl(archiveMetadataUrlWithPrefix)\n",
    "    eadid.append(getTextBeneathTag(root, \"eadid\", \"Encoded Archival Description Identifier\"))\n",
    "    ut.append(getTextBeneathTag(root, \"unittitle\", \"Unit Title\"))\n",
    "    ui.append(getTextBeneathTag(root, \"unitid\", \"Unit Identifier\"))\n",
    "    ud.append(getTextBeneathTag(root, \"unitdate\", \"Unit Date\"))\n",
    "    gn.append(getTextBeneathTag(root, \"geogname\", \"Geography Name\"))\n",
    "    lm.append(getTextBeneathTag(root, \"langmaterial\", \"Language of Materials\"))\n",
    "    sc.append(getTextBeneathTag(root, \"scopecontent\", \"Scope and Contents\"))\n",
    "    bh.append(getTextBeneathTag(root, \"bioghist\", \"Biographical / Historical\"))\n",
    "    pi.append(getTextBeneathTag(root, \"processinfo\", \"Processing Information\"))\n",
    "    resumptionToken = getTextBeneathTag(root, \"resumptionToken\", \"\")\n",
    "    \n",
    "    if len(resumptionToken) == 0:\n",
    "        more = False\n",
    "    i = 1\n",
    "    \n",
    "    while more:\n",
    "        archiveMetadataUrlWithToken = archiveMetadataUrlShort + \"resumptionToken=\" + resumptionToken[0]\n",
    "        root = getRootFromUrl(archiveMetadataUrlWithToken)\n",
    "        eadid.append(getTextBeneathTag(root, \"eadid\", \"Encoded Archival Description Identifier\"))\n",
    "        ut.append(getTextBeneathTag(root, \"unittitle\", \"Unit Title\"))\n",
    "        ui.append(getTextBeneathTag(root, \"unitid\", \"Unit Identifier\"))\n",
    "        ud.append(getTextBeneathTag(root, \"unitdate\", \"Unit Date\"))\n",
    "        gn.append(getTextBeneathTag(root, \"geogname\", \"Geography Name\"))\n",
    "        lm.append(getTextBeneathTag(root, \"langmaterial\", \"Language of Materials\"))\n",
    "        sc.append(getTextBeneathTag(root, \"scopecontent\", \"Scope and Contents\"))\n",
    "        bh.append(getTextBeneathTag(root, \"bioghist\", \"Biographical / Historical\"))\n",
    "        pi.append(getTextBeneathTag(root, \"processinfo\", \"Processing Information\"))\n",
    "        resumptionToken = getTextBeneathTag(root, \"resumptionToken\", \"\")\n",
    "        if len(resumptionToken) == 0:\n",
    "            more = False\n",
    "        i += 1\n",
    "    \n",
    "    print(str(i) + \" resumption tokens\")\n",
    "    return eadid, ut, ui, ud, gn, lm, sc, bh, pi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1081 resumption tokens\n"
     ]
    }
   ],
   "source": [
    "url = \"http://lac-archives-live.is.ed.ac.uk:8082/?verb=ListRecords&\"\n",
    "startPrefix = \"metadataPrefix=oai_ead\"\n",
    "eadid = [] # List of fonds-level identifiers\n",
    "ut = [] # List of fonds, series, and item titles\n",
    "ui = [] # List of fonds, series, and item identifiers\n",
    "ud = [] # List of fonds, series, and item dates\n",
    "gn = [] # List of fonds, series, and item associated geographic locations \n",
    "lm = [] # List of fonds, series, and item material languages\n",
    "sc = [] # List of fonds, series, and item \"Scope and Contents\" descriptions\n",
    "bh = [] # List of fonds, series, and item \"Biographical / Historical\" descriptions\n",
    "pi = []  # List of fonds, series, and item \"Processing Information\" descriptions\n",
    "\n",
    "eadid, ut, ui, ud, gn, lm, sc, bh, pi = getDescriptiveMetadata(True, url, startPrefix, eadid, ut, ui, ud, gn, lm, sc, bh, pi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1081\n",
      "1081\n",
      "1081\n",
      "1081\n",
      "1081\n",
      "1081\n",
      "1081\n",
      "1081\n",
      "1081\n"
     ]
    }
   ],
   "source": [
    "print(len(eadid))\n",
    "print(len(ut))\n",
    "print(len(ui))\n",
    "print(len(ud))\n",
    "print(len(gn))\n",
    "print(len(lm))\n",
    "print(len(sc))\n",
    "print(len(bh))\n",
    "print(len(pi))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "124\n",
      "124\n",
      "124\n",
      "116\n",
      "125\n",
      "119\n",
      "2\n",
      "1\n"
     ]
    }
   ],
   "source": [
    "i = 0\n",
    "print(len(eadid[i]))\n",
    "print(len(ut[i]))\n",
    "print(len(ui[i]))\n",
    "print(len(ud[i]))\n",
    "print(len(gn[i]))\n",
    "print(len(lm[i]))\n",
    "print(len(sc[i]))\n",
    "print(len(bh[i]))\n",
    "print(len(pi[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def deduplicateDescriptions(metadata_field_list):\n",
    "    unique_descs = []\n",
    "    for fonds in metadata_field_list:\n",
    "        unique_descs += [list(set(fonds))]\n",
    "    assert len(metadata_field_list) == len(unique_descs)\n",
    "    return unique_descs\n",
    "unique_sc = deduplicateDescriptions(sc)\n",
    "unique_bh = deduplicateDescriptions(bh)\n",
    "unique_pi = deduplicateDescriptions(pi)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"transforming\"></a>\n",
    "## II. Transforming\n",
    "Create a table (pandas DataFrame) of the metadata without multi-sentence descriptions and plain text files of the descriptive metadata."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "import string\n",
    "import csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Coll-1064\n"
     ]
    }
   ],
   "source": [
    "flatten = []\n",
    "for sublist in eadid:\n",
    "    for item in sublist:\n",
    "        flatten += [item]\n",
    "print(flatten[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>eadid</th>\n",
       "      <th>unit_title</th>\n",
       "      <th>unit_identifier</th>\n",
       "      <th>unit_date</th>\n",
       "      <th>geography</th>\n",
       "      <th>language</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Coll-1064</td>\n",
       "      <td>[Papers of Professor Walter Ledermann, 1 (37),...</td>\n",
       "      <td>[Coll-1064, Coll-1064/1, Coll-1064/2, Coll-106...</td>\n",
       "      <td>[1937-1954, 2 Feb 1937, 10 Feb 1937, 16 Feb 19...</td>\n",
       "      <td>[Edinburgh (Scotland), Edinburgh (Scotland), E...</td>\n",
       "      <td>[\\n      English\\n    , English, English, Engl...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Coll-31</td>\n",
       "      <td>[Drawings from the Office of Sir Rowand Anders...</td>\n",
       "      <td>[Coll-31, Coll-31/1, Coll-31/1/1, Coll-31/1/1/...</td>\n",
       "      <td>[1814-1924, 1874-1905, 1874-1879, 1874-1875, 1...</td>\n",
       "      <td>[]</td>\n",
       "      <td>[\\n      English\\n    , English, English, Engl...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Coll-51</td>\n",
       "      <td>[Papers of Sir Roderick Impey Murchison and hi...</td>\n",
       "      <td>[Coll-51, Coll-51/1, Coll-51/2, Coll-51/2/1, C...</td>\n",
       "      <td>[1771-1935, 1723-1935, 1770-1938, 1770-1938, 1...</td>\n",
       "      <td>[Calcutta (India), Europe, Scotland, Tarradale...</td>\n",
       "      <td>[\\n      English\\n    , English, English, Engl...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Coll-204</td>\n",
       "      <td>[Lecture Notes of John Robison, Introductions,...</td>\n",
       "      <td>[Coll-204, Coll-204/1, Coll-204/2, Coll-204/3,...</td>\n",
       "      <td>[c1779-c1801, c1779-c1801, c1804, c1802, c1780...</td>\n",
       "      <td>[Edinburgh (Scotland), Glasgow Lanarkshire Sco...</td>\n",
       "      <td>[\\n      English\\n    , English., English Lati...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Coll-206</td>\n",
       "      <td>[Records of the Wernerian Natural History Soci...</td>\n",
       "      <td>[Coll-206, Coll-206/1, Coll-206/1/1, Coll-206/...</td>\n",
       "      <td>[1808-1858, 12 January 1808-16 April 1858, 12 ...</td>\n",
       "      <td>[Edinburgh (Scotland), Freiburg im Breisgau (G...</td>\n",
       "      <td>[\\n      English\\n    , English, English, Engl...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       eadid                                         unit_title  \\\n",
       "0  Coll-1064  [Papers of Professor Walter Ledermann, 1 (37),...   \n",
       "1    Coll-31  [Drawings from the Office of Sir Rowand Anders...   \n",
       "2    Coll-51  [Papers of Sir Roderick Impey Murchison and hi...   \n",
       "3   Coll-204  [Lecture Notes of John Robison, Introductions,...   \n",
       "4   Coll-206  [Records of the Wernerian Natural History Soci...   \n",
       "\n",
       "                                     unit_identifier  \\\n",
       "0  [Coll-1064, Coll-1064/1, Coll-1064/2, Coll-106...   \n",
       "1  [Coll-31, Coll-31/1, Coll-31/1/1, Coll-31/1/1/...   \n",
       "2  [Coll-51, Coll-51/1, Coll-51/2, Coll-51/2/1, C...   \n",
       "3  [Coll-204, Coll-204/1, Coll-204/2, Coll-204/3,...   \n",
       "4  [Coll-206, Coll-206/1, Coll-206/1/1, Coll-206/...   \n",
       "\n",
       "                                           unit_date  \\\n",
       "0  [1937-1954, 2 Feb 1937, 10 Feb 1937, 16 Feb 19...   \n",
       "1  [1814-1924, 1874-1905, 1874-1879, 1874-1875, 1...   \n",
       "2  [1771-1935, 1723-1935, 1770-1938, 1770-1938, 1...   \n",
       "3  [c1779-c1801, c1779-c1801, c1804, c1802, c1780...   \n",
       "4  [1808-1858, 12 January 1808-16 April 1858, 12 ...   \n",
       "\n",
       "                                           geography  \\\n",
       "0  [Edinburgh (Scotland), Edinburgh (Scotland), E...   \n",
       "1                                                 []   \n",
       "2  [Calcutta (India), Europe, Scotland, Tarradale...   \n",
       "3  [Edinburgh (Scotland), Glasgow Lanarkshire Sco...   \n",
       "4  [Edinburgh (Scotland), Freiburg im Breisgau (G...   \n",
       "\n",
       "                                            language  \n",
       "0  [\\n      English\\n    , English, English, Engl...  \n",
       "1  [\\n      English\\n    , English, English, Engl...  \n",
       "2  [\\n      English\\n    , English, English, Engl...  \n",
       "3  [\\n      English\\n    , English., English Lati...  \n",
       "4  [\\n      English\\n    , English, English, Engl...  "
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.DataFrame.from_dict({\"eadid\":flatten,\"unit_title\":ut, \"unit_identifier\":ui, \"unit_date\":ud, \"geography\":gn, \"language\":lm})\n",
    "# df = pd.read_csv(\"CRC_units-grouped-by-fonds.csv\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1081, 6)\n"
     ]
    }
   ],
   "source": [
    "print(df.shape)\n",
    "df.to_csv(\"CRC_units-grouped-by-fonds.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Coll-1064',\n",
       " 'Coll-31',\n",
       " 'Coll-51',\n",
       " 'Coll-204',\n",
       " 'Coll-206',\n",
       " 'Coll 205',\n",
       " 'Coll-1443',\n",
       " 'Coll-1444',\n",
       " 'Coll-1391',\n",
       " 'Coll-1371',\n",
       " 'Coll-1373',\n",
       " 'Coll-96',\n",
       " 'Coll-891',\n",
       " 'Coll-623',\n",
       " 'Coll-58',\n",
       " 'Coll-60',\n",
       " 'Coll-61',\n",
       " 'Coll-56',\n",
       " 'Coll-550',\n",
       " 'Coll-55',\n",
       " 'Coll-548',\n",
       " 'Coll-549',\n",
       " 'Coll-89',\n",
       " 'Coll-540',\n",
       " 'Coll-542',\n",
       " 'Coll-547',\n",
       " 'Coll-53',\n",
       " 'Coll-522',\n",
       " 'Coll-523',\n",
       " 'Coll-516',\n",
       " 'Coll-518',\n",
       " 'Coll-521',\n",
       " 'Coll-507',\n",
       " 'Coll-890',\n",
       " 'Coll-509',\n",
       " 'Coll-513',\n",
       " 'Coll-499',\n",
       " 'Coll-500',\n",
       " 'Coll-49',\n",
       " 'Coll-487',\n",
       " 'Coll-494',\n",
       " 'Coll-48',\n",
       " 'Coll-475',\n",
       " 'Coll-478',\n",
       " 'Coll-887',\n",
       " 'Coll-454',\n",
       " 'Coll-461',\n",
       " 'Coll-462',\n",
       " 'Coll-468',\n",
       " 'Coll-439',\n",
       " 'Coll-443',\n",
       " 'Coll-444',\n",
       " 'Coll-453',\n",
       " 'Coll-42',\n",
       " 'Coll-43',\n",
       " 'Coll-88',\n",
       " 'Coll-417',\n",
       " 'Coll-426',\n",
       " 'Coll-405',\n",
       " 'Coll-39',\n",
       " 'Coll-40',\n",
       " 'Coll-392',\n",
       " 'Coll-35',\n",
       " 'Coll-36',\n",
       " 'Coll-38',\n",
       " 'Coll-344',\n",
       " 'Coll-84',\n",
       " 'Coll-34',\n",
       " 'Coll-333',\n",
       " 'Coll-335',\n",
       " 'Coll-341',\n",
       " 'Coll-283',\n",
       " 'Coll-302',\n",
       " 'Coll-307',\n",
       " 'Coll-311',\n",
       " 'Coll-275',\n",
       " 'Coll-276',\n",
       " '',\n",
       " 'Coll-282',\n",
       " 'Coll-265',\n",
       " 'Coll-269',\n",
       " 'Coll-270',\n",
       " 'Coll-271',\n",
       " 'Coll-26',\n",
       " 'Coll-256',\n",
       " 'Coll-257',\n",
       " 'Coll-260',\n",
       " 'Coll-82',\n",
       " 'Coll-251',\n",
       " 'Coll-253',\n",
       " 'Coll-232',\n",
       " 'Coll-233',\n",
       " 'Coll-238',\n",
       " 'Coll-241',\n",
       " 'Coll-225',\n",
       " 'Coll-227',\n",
       " 'Coll-230',\n",
       " 'Coll-231',\n",
       " 'Coll-819',\n",
       " 'Coll-208',\n",
       " 'Coll-219',\n",
       " 'Coll-220',\n",
       " 'Coll-223',\n",
       " 'Coll-20',\n",
       " 'Coll-200',\n",
       " 'Coll-201',\n",
       " 'Coll-207',\n",
       " 'Coll-195',\n",
       " 'Coll-198',\n",
       " 'Coll-817',\n",
       " 'Coll-19',\n",
       " 'Coll-177',\n",
       " 'Coll-187',\n",
       " 'Coll-191',\n",
       " 'Coll-17',\n",
       " 'Coll-165',\n",
       " 'Coll-175',\n",
       " 'Coll-15',\n",
       " 'Coll-161',\n",
       " 'Coll-162',\n",
       " 'Coll-94',\n",
       " 'Coll-818',\n",
       " 'Coll-164',\n",
       " 'Coll-134',\n",
       " 'Coll-135',\n",
       " 'Coll-139',\n",
       " '',\n",
       " 'Coll-126',\n",
       " 'Coll-127',\n",
       " 'Coll-132',\n",
       " 'Coll-100',\n",
       " 'Coll-811',\n",
       " 'Coll-103',\n",
       " 'Coll-125',\n",
       " 'Coll-810',\n",
       " 'Coll-81',\n",
       " 'Coll-809',\n",
       " 'Coll-807',\n",
       " 'Coll-808',\n",
       " 'Coll-806',\n",
       " 'Coll-805',\n",
       " 'Coll-802',\n",
       " 'Coll-95',\n",
       " 'Coll-804',\n",
       " 'Coll-800',\n",
       " 'Coll-801',\n",
       " 'Coll-80',\n",
       " 'Coll-8',\n",
       " 'Coll-799',\n",
       " 'Coll-797',\n",
       " 'Coll-795',\n",
       " 'Coll-796',\n",
       " 'Coll-793',\n",
       " 'Coll-93',\n",
       " 'Coll-794',\n",
       " 'Coll-792',\n",
       " 'Coll-791',\n",
       " 'Coll-79',\n",
       " 'Coll-790',\n",
       " 'Coll-785',\n",
       " 'Coll-788',\n",
       " 'Coll-78',\n",
       " 'Coll-76',\n",
       " 'Coll-734',\n",
       " 'Coll-90',\n",
       " 'Coll-731',\n",
       " 'Coll-732',\n",
       " 'Coll-729',\n",
       " 'Coll-730',\n",
       " 'Coll-726',\n",
       " 'Coll-728',\n",
       " 'Coll-724',\n",
       " 'Coll-725',\n",
       " 'Coll-721',\n",
       " 'Coll-723',\n",
       " 'Coll-9',\n",
       " 'Coll-715',\n",
       " 'Coll-719',\n",
       " 'Coll-720',\n",
       " 'Coll-710',\n",
       " 'Coll-71',\n",
       " 'Coll-708',\n",
       " 'Coll-706',\n",
       " 'Coll-707',\n",
       " 'Coll-703',\n",
       " 'Coll-893',\n",
       " 'Coll-704',\n",
       " 'Coll-701',\n",
       " 'Coll-702',\n",
       " 'Coll-7',\n",
       " 'Coll-70',\n",
       " 'Coll-697',\n",
       " 'Coll-691',\n",
       " 'Coll-696',\n",
       " 'Coll-67',\n",
       " 'Coll-68',\n",
       " 'Coll-894',\n",
       " 'Coll-688',\n",
       " 'Coll-66',\n",
       " 'Coll-668',\n",
       " 'Coll-65',\n",
       " 'Coll-649',\n",
       " 'Coll-652',\n",
       " 'Coll-646',\n",
       " 'Coll-647',\n",
       " 'Coll-648',\n",
       " 'Coll-643',\n",
       " 'Coll-892',\n",
       " 'Coll-644',\n",
       " 'Coll-645',\n",
       " 'Coll-63',\n",
       " '',\n",
       " 'Coll-630',\n",
       " 'Coll-624',\n",
       " 'Coll-625',\n",
       " 'Coll-626',\n",
       " 'Coll-62',\n",
       " 'Coll-622',\n",
       " 'Coll-1039',\n",
       " 'Coll-541',\n",
       " 'Coll-1041',\n",
       " 'Coll-1038',\n",
       " 'Coll-1037',\n",
       " 'Coll-1036',\n",
       " 'Coll-1034',\n",
       " 'Coll-1030',\n",
       " 'Coll-1032',\n",
       " 'Coll-1024',\n",
       " 'Coll-1021',\n",
       " 'Coll-1018',\n",
       " 'Coll-54',\n",
       " 'Coll-1014',\n",
       " 'Coll-1010',\n",
       " 'Coll-1000',\n",
       " 'Coll-1001',\n",
       " 'Coll-377',\n",
       " '',\n",
       " 'Coll-21',\n",
       " 'Coll-1050',\n",
       " 'Coll-1048',\n",
       " 'Coll-1046',\n",
       " 'Coll-1044',\n",
       " 'Coll-1142',\n",
       " 'Coll-1170',\n",
       " 'Coll-1158',\n",
       " 'Coll-1157',\n",
       " 'Coll-1156',\n",
       " 'Coll-1155',\n",
       " 'Coll-1154',\n",
       " 'Coll-1153',\n",
       " 'Coll-1152',\n",
       " 'Coll-1150',\n",
       " 'Coll-1149',\n",
       " 'Coll-1148',\n",
       " 'Coll-1166',\n",
       " 'Coll-1146',\n",
       " 'Coll-1145',\n",
       " 'Coll-1143',\n",
       " 'Coll-1140',\n",
       " 'Coll-1139',\n",
       " 'Coll-1138',\n",
       " 'Coll-1137',\n",
       " 'Coll-1136',\n",
       " 'Coll-1135',\n",
       " 'Coll-1134',\n",
       " 'Coll-1165',\n",
       " 'Coll-1133',\n",
       " 'Coll-1130',\n",
       " 'Coll-1129',\n",
       " 'Coll-1127',\n",
       " 'Coll-1126',\n",
       " 'Coll-1125',\n",
       " 'Coll-1124',\n",
       " 'Coll-1123',\n",
       " 'Coll-1122',\n",
       " 'Coll-1121',\n",
       " 'Coll-1164',\n",
       " 'Coll-1119',\n",
       " 'Coll-1118',\n",
       " 'Coll-1117',\n",
       " 'Coll-1116',\n",
       " 'Coll-1115',\n",
       " 'Coll-1114',\n",
       " 'Coll-1111',\n",
       " 'Coll-1110',\n",
       " 'Coll-1109',\n",
       " 'Coll-1108',\n",
       " 'Coll-1163',\n",
       " 'Coll-1107',\n",
       " 'Coll-1106',\n",
       " 'Coll-1105',\n",
       " 'Coll-1104',\n",
       " 'Coll-1103',\n",
       " 'Coll-1102',\n",
       " 'Coll-1101',\n",
       " 'Coll-1100',\n",
       " 'Coll-1099',\n",
       " 'Coll-1097',\n",
       " 'Coll-1162',\n",
       " 'Coll-1096',\n",
       " 'Coll-1093',\n",
       " 'Coll-1092',\n",
       " 'Coll-1091',\n",
       " 'Coll-1090',\n",
       " 'Coll-1089',\n",
       " 'Coll-1088',\n",
       " 'Coll-1087',\n",
       " 'Coll-1086',\n",
       " 'Coll-1085',\n",
       " 'Coll-1161',\n",
       " 'Coll-1084',\n",
       " 'Coll-1083',\n",
       " 'Coll-1082',\n",
       " 'Coll-1081',\n",
       " 'Coll-1080',\n",
       " 'Coll-1079',\n",
       " 'Coll-1077',\n",
       " 'Coll-1076',\n",
       " 'Coll-1075',\n",
       " 'Coll-1072',\n",
       " 'Coll-1160',\n",
       " 'Coll-1071',\n",
       " 'Coll-1070',\n",
       " 'Coll-1069',\n",
       " 'Coll-1068',\n",
       " 'Coll-1066',\n",
       " 'Coll-1063',\n",
       " 'Coll-1062',\n",
       " 'Coll-1061',\n",
       " 'Coll-1060',\n",
       " 'Coll-1059',\n",
       " 'Coll-1159',\n",
       " 'Coll-1058',\n",
       " 'Coll-1055',\n",
       " 'Coll-1054',\n",
       " 'Coll-1052',\n",
       " 'Coll-1028',\n",
       " 'Coll-1004',\n",
       " 'Coll-1466',\n",
       " 'Coll-1319',\n",
       " 'Coll-1522',\n",
       " 'Coll-1521',\n",
       " 'Coll-1497',\n",
       " 'Coll-1370',\n",
       " 'Coll-11',\n",
       " 'Coll-1296',\n",
       " 'Coll-1548',\n",
       " 'Coll-1490',\n",
       " 'Coll-1181',\n",
       " 'Coll-1535',\n",
       " 'Coll-1288',\n",
       " 'Coll-1547',\n",
       " 'Coll-1553',\n",
       " 'Coll-1552',\n",
       " 'Coll-1551',\n",
       " 'Coll-1550',\n",
       " 'Coll-1544',\n",
       " 'Coll-544',\n",
       " 'Coll-1608',\n",
       " 'Coll-1558',\n",
       " 'Coll-1557',\n",
       " 'Coll-1556',\n",
       " 'Coll-1555',\n",
       " 'Coll-1554',\n",
       " 'Coll-1549',\n",
       " 'Coll-1546',\n",
       " 'Coll-1530',\n",
       " 'Coll-1526',\n",
       " 'Coll-1525',\n",
       " 'Coll-1524',\n",
       " 'Coll-1523',\n",
       " 'Coll-1519',\n",
       " 'Coll-1517',\n",
       " 'Coll-1515',\n",
       " 'Coll-1514',\n",
       " 'Coll-1507',\n",
       " 'Coll-1545',\n",
       " 'Coll-1504',\n",
       " 'Coll-1502',\n",
       " 'Coll-1501',\n",
       " 'Coll-1500',\n",
       " 'Coll-1543',\n",
       " 'Coll-1542',\n",
       " 'Coll-1541',\n",
       " 'Coll-1539',\n",
       " 'Coll-1534',\n",
       " 'Coll-1533',\n",
       " 'Coll-1532',\n",
       " 'Coll-1499',\n",
       " 'Coll-1498',\n",
       " 'Coll-1483',\n",
       " 'Coll-1482',\n",
       " 'Coll-1481',\n",
       " 'Coll-1480',\n",
       " 'GB 237 Coll-1492',\n",
       " 'Coll-1491',\n",
       " 'Coll-1489',\n",
       " 'Coll-1488',\n",
       " 'Coll-1487',\n",
       " 'Coll-1486',\n",
       " 'Coll-1485',\n",
       " 'Coll-1484',\n",
       " 'Coll-1479',\n",
       " 'Coll-1478',\n",
       " 'Coll-1476',\n",
       " 'Coll-1475',\n",
       " 'Coll-1462',\n",
       " 'Coll-1461',\n",
       " 'Coll-1460',\n",
       " 'Coll-1474',\n",
       " 'Coll-1472',\n",
       " 'Coll-1471',\n",
       " 'Coll-1470',\n",
       " 'Coll-1469',\n",
       " 'Coll-1465',\n",
       " 'Coll-1464',\n",
       " 'Coll-1463',\n",
       " 'Coll-1459',\n",
       " 'Coll-1458',\n",
       " 'Coll-1457',\n",
       " 'Coll-1456',\n",
       " 'Coll-1455',\n",
       " 'Coll-1454',\n",
       " 'Coll-1453',\n",
       " 'Coll-1452',\n",
       " 'Coll-1451',\n",
       " 'Coll-1448',\n",
       " 'Coll-1446',\n",
       " 'Coll-1442',\n",
       " 'Coll-1441',\n",
       " 'Coll-1439',\n",
       " 'Coll-1438',\n",
       " 'Coll-1437',\n",
       " 'Coll-1436',\n",
       " 'Coll-1435',\n",
       " 'Coll-1432',\n",
       " 'Coll-1431',\n",
       " 'Coll-1429',\n",
       " 'Coll-1428',\n",
       " 'Coll-1427',\n",
       " 'Coll-1426',\n",
       " 'Coll-1425',\n",
       " 'Coll-1424',\n",
       " 'Coll-1423',\n",
       " 'Coll-1422',\n",
       " 'Coll-1421',\n",
       " 'Coll-1419',\n",
       " 'Coll-1418',\n",
       " 'Coll-1405',\n",
       " 'Coll-1404',\n",
       " 'Coll-1403',\n",
       " 'Coll-1402',\n",
       " 'Coll-1401',\n",
       " 'Coll-1400',\n",
       " 'Coll-1417',\n",
       " 'Coll-1416',\n",
       " 'Coll-1415',\n",
       " 'Coll-1414',\n",
       " 'Coll-1413',\n",
       " 'Coll-1412',\n",
       " 'Coll-1411',\n",
       " 'Coll-1410',\n",
       " 'Coll-1398',\n",
       " 'Coll-1397',\n",
       " 'Coll-1379',\n",
       " 'Coll-1236',\n",
       " 'Coll-1235',\n",
       " 'Coll-1234',\n",
       " 'Coll-1182',\n",
       " 'Coll-1180',\n",
       " 'Coll-1179',\n",
       " 'Coll-1776',\n",
       " 'Coll-1175',\n",
       " 'Coll-1174',\n",
       " 'Coll-1173',\n",
       " 'Coll-1378',\n",
       " 'Coll-1172',\n",
       " 'Coll-1171',\n",
       " 'Coll-1168',\n",
       " 'Coll-1375',\n",
       " 'Coll-1374',\n",
       " 'Coll-1372',\n",
       " 'Coll-1369',\n",
       " 'Coll-1363',\n",
       " 'Coll-1357',\n",
       " 'Coll-1351',\n",
       " 'Coll-1350',\n",
       " 'Coll-1396',\n",
       " 'Coll-1329',\n",
       " 'Coll-1328',\n",
       " 'Coll-1327',\n",
       " 'Coll-1326',\n",
       " 'Coll-1325',\n",
       " 'Coll-1324',\n",
       " 'Coll-1323',\n",
       " 'Coll-1322',\n",
       " 'Coll-1321',\n",
       " 'Coll-1318',\n",
       " 'Coll-1395',\n",
       " 'Coll-1317',\n",
       " 'Coll-1316',\n",
       " 'Coll-1315',\n",
       " 'Coll-1314',\n",
       " 'Coll-1313',\n",
       " 'Coll-1312',\n",
       " 'Coll-1311',\n",
       " 'Coll-1309',\n",
       " 'Coll-1308',\n",
       " 'ccColl-1307',\n",
       " 'Coll-1394',\n",
       " 'Coll-1306',\n",
       " 'Coll-1305',\n",
       " 'Coll-1304',\n",
       " 'Coll-1302',\n",
       " 'Coll-1301',\n",
       " 'Coll-1300',\n",
       " 'Coll-1299',\n",
       " 'Coll-1298',\n",
       " 'Coll-1297',\n",
       " 'Coll-1294',\n",
       " 'Coll-1293',\n",
       " 'Coll-1292',\n",
       " 'Coll-1291',\n",
       " 'Coll-1290',\n",
       " 'Coll-1289',\n",
       " 'Coll-1287',\n",
       " 'Coll-1285',\n",
       " 'Coll-1283',\n",
       " 'Coll-1282',\n",
       " 'Coll-1281',\n",
       " 'Coll-1387',\n",
       " 'Coll-1280',\n",
       " 'Coll-1279',\n",
       " 'Coll-1277',\n",
       " 'Coll-1276',\n",
       " 'Coll-1275',\n",
       " 'Coll-1274',\n",
       " 'Coll-1273',\n",
       " 'Coll-1272',\n",
       " 'Coll-1271',\n",
       " 'Coll-1270',\n",
       " 'Coll-1385',\n",
       " 'Coll-1269',\n",
       " 'Coll-1267',\n",
       " 'Coll-1265',\n",
       " 'Coll-1264',\n",
       " 'Coll-1263',\n",
       " 'Coll-1262',\n",
       " 'Coll-1261',\n",
       " 'Coll-1260',\n",
       " 'Coll-1259',\n",
       " 'Coll-1384',\n",
       " 'Coll-1258',\n",
       " 'Coll-1257',\n",
       " 'Coll-1256',\n",
       " 'Coll-1254',\n",
       " 'Coll-1253',\n",
       " 'Coll-1252',\n",
       " 'Coll-1251',\n",
       " 'Coll-1250',\n",
       " 'Coll-1248',\n",
       " 'Coll-1247',\n",
       " 'Coll-1383',\n",
       " 'Coll-1246',\n",
       " 'Coll-1245',\n",
       " 'Coll-1244',\n",
       " 'Coll-1243',\n",
       " 'Coll-1242',\n",
       " 'Coll-1241',\n",
       " 'Coll-1240',\n",
       " 'Coll-1239',\n",
       " 'Coll-1238',\n",
       " 'Coll-1237',\n",
       " 'BAI',\n",
       " 'Coll-1430',\n",
       " 'Coll-1477',\n",
       " 'EUA CA2',\n",
       " 'Coll-27',\n",
       " 'Coll-1255',\n",
       " 'La',\n",
       " 'Coll-29',\n",
       " 'Coll-57',\n",
       " 'Coll-1586',\n",
       " 'P.Oxy',\n",
       " 'Coll-41',\n",
       " 'Coll-1364',\n",
       " 'EUA IN1',\n",
       " 'EUA GD58',\n",
       " 'EUA GD59',\n",
       " 'Coll-74',\n",
       " 'EUA IN14',\n",
       " '',\n",
       " '',\n",
       " 'Coll-1167',\n",
       " 'Coll-14',\n",
       " 'GD3',\n",
       " 'GD5',\n",
       " 'GD6',\n",
       " 'GD7',\n",
       " 'GD10',\n",
       " 'EUA GD4',\n",
       " 'Coll-46',\n",
       " 'GD11',\n",
       " 'GD12',\n",
       " 'GD13',\n",
       " 'GD14',\n",
       " 'GD15',\n",
       " 'GD16',\n",
       " 'GD17',\n",
       " 'GD18',\n",
       " 'GD19',\n",
       " 'GD21',\n",
       " 'GD22',\n",
       " 'GD23',\n",
       " 'GD24',\n",
       " 'GD25',\n",
       " 'GD27',\n",
       " 'GD30',\n",
       " 'GD31',\n",
       " 'GD32',\n",
       " 'GD33',\n",
       " 'GD34',\n",
       " 'GD35',\n",
       " 'GD36',\n",
       " 'GD37',\n",
       " 'GD38',\n",
       " 'GD39',\n",
       " 'GD40',\n",
       " 'GD41',\n",
       " 'GD42',\n",
       " 'GD43',\n",
       " 'GD44',\n",
       " 'GD45',\n",
       " 'GD46',\n",
       " 'GD47',\n",
       " 'GD48',\n",
       " 'GD49',\n",
       " 'GD50',\n",
       " 'GD51',\n",
       " 'GD52',\n",
       " 'GD53',\n",
       " 'GD54',\n",
       " 'GD55',\n",
       " 'GD57',\n",
       " 'GD20',\n",
       " 'GD26',\n",
       " 'GD29',\n",
       " 'GD56',\n",
       " 'GB 238 GD2',\n",
       " 'GB 237 Coll-653',\n",
       " 'GB 237 Coll-735',\n",
       " 'GB 237 Coll-754',\n",
       " 'Coll-1561',\n",
       " 'Coll-1560',\n",
       " 'Coll-1635',\n",
       " 'Coll-1636',\n",
       " 'Coll-1640',\n",
       " 'Coll-1622',\n",
       " 'Coll-1623',\n",
       " 'Coll-1625',\n",
       " 'Coll-1616',\n",
       " '',\n",
       " 'Coll-1620',\n",
       " 'Coll-1621',\n",
       " 'Coll-1653',\n",
       " 'Coll-1611',\n",
       " 'Coll-1612',\n",
       " 'Coll-1613',\n",
       " 'Coll-1614',\n",
       " 'Coll-1604',\n",
       " 'Coll-1607',\n",
       " 'Coll-1609',\n",
       " 'Coll-1610',\n",
       " 'Coll-1595',\n",
       " 'Coll-1601',\n",
       " 'Coll-1624',\n",
       " 'Coll-1602',\n",
       " 'Coll-1603',\n",
       " 'Coll-1590',\n",
       " 'Coll-1593',\n",
       " 'Coll-1594',\n",
       " 'Coll-1584',\n",
       " 'Coll-1585',\n",
       " 'Coll-1587',\n",
       " 'Coll-1588',\n",
       " 'Coll-1581',\n",
       " 'Coll-1650',\n",
       " 'Coll-1582',\n",
       " 'Coll-1579',\n",
       " 'Coll-1580',\n",
       " 'Coll-1572',\n",
       " 'Coll-1574',\n",
       " 'Coll-1575',\n",
       " 'Coll-1576',\n",
       " 'Coll-1570',\n",
       " 'Coll-1571',\n",
       " 'Coll-1564',\n",
       " 'Coll-1648',\n",
       " 'Coll-1565',\n",
       " 'Coll-1566',\n",
       " 'Coll-1569',\n",
       " 'Coll-1562',\n",
       " 'Coll-1538',\n",
       " 'Coll-1559',\n",
       " 'Coll-1645',\n",
       " 'Coll-1646',\n",
       " 'Coll-1647',\n",
       " 'Coll-1626',\n",
       " 'Coll-203',\n",
       " 'Coll-99',\n",
       " 'Coll-411',\n",
       " 'Coll-1434',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " 'EUA GD20',\n",
       " 'EUA CA5',\n",
       " 'EUA GD1',\n",
       " 'EUD GD5',\n",
       " 'EUA GD6',\n",
       " 'EUA GD9',\n",
       " 'EUA GD25',\n",
       " 'EUA GD29',\n",
       " '',\n",
       " '',\n",
       " 'Coll-1362',\n",
       " '',\n",
       " 'Coll-1057',\n",
       " 'EUA IN2',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " 'PJM',\n",
       " '',\n",
       " 'Coll-218',\n",
       " '',\n",
       " 'Coll-1665',\n",
       " 'Coll-1662',\n",
       " 'Coll-1671',\n",
       " 'Coll-1658',\n",
       " 'Coll-1657',\n",
       " 'Coll-1666',\n",
       " 'Coll-1667',\n",
       " 'Coll-1668',\n",
       " 'Coll-1669',\n",
       " 'Coll-1670',\n",
       " 'Coll-1673',\n",
       " 'Coll-1674',\n",
       " 'Coll-1687',\n",
       " 'Coll-1679',\n",
       " 'Coll-1680',\n",
       " 'Coll-1681',\n",
       " 'Coll-1682',\n",
       " 'Coll-1683',\n",
       " 'Coll-1684',\n",
       " 'Coll-1685',\n",
       " 'Coll-1686',\n",
       " 'Coll-1655',\n",
       " 'Coll-25',\n",
       " 'Coll-1656',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " 'Coll-1693',\n",
       " 'Coll-1691',\n",
       " 'Coll-1692',\n",
       " 'Coll-1694',\n",
       " 'Coll-1695',\n",
       " 'Coll-1696',\n",
       " 'Coll-1573',\n",
       " 'Coll-1697',\n",
       " 'Coll-1445',\n",
       " 'Coll-1310',\n",
       " '',\n",
       " 'Coll-252',\n",
       " 'Coll-91',\n",
       " 'Coll-86',\n",
       " 'Coll-1699',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " 'Coll-1703',\n",
       " '',\n",
       " 'Coll-1704',\n",
       " 'Coll-1705',\n",
       " 'Coll-1707',\n",
       " 'Coll-1708',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " 'Coll-1712',\n",
       " 'Coll-1713',\n",
       " 'Coll-1651',\n",
       " 'Coll-1714',\n",
       " 'Coll-1718',\n",
       " 'Coll-1719',\n",
       " 'Coll-1720',\n",
       " 'Coll-1721',\n",
       " 'Coll-1723',\n",
       " 'EUA GD18',\n",
       " '',\n",
       " 'Coll-1727',\n",
       " 'Coll-1728',\n",
       " '',\n",
       " 'Coll-1729',\n",
       " '',\n",
       " 'Coll-1732',\n",
       " 'Coll-1731',\n",
       " 'Coll-1733',\n",
       " '',\n",
       " 'Coll-1735',\n",
       " 'Coll-1744',\n",
       " 'Coll-1743',\n",
       " 'Coll-1738',\n",
       " 'Coll-1739',\n",
       " 'Coll-1740',\n",
       " 'Coll-1741',\n",
       " 'Coll-1742',\n",
       " 'Coll-1745',\n",
       " 'Coll-1746',\n",
       " 'Coll-1747',\n",
       " 'Coll-146a',\n",
       " 'Coll-1749',\n",
       " '',\n",
       " 'Coll-37',\n",
       " 'Coll-16',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " 'Coll-1754',\n",
       " 'Coll-1755',\n",
       " 'Coll-1756',\n",
       " 'Coll-1757',\n",
       " 'Coll-1758',\n",
       " '',\n",
       " 'Coll-1767',\n",
       " 'Coll-1768',\n",
       " 'Coll-1769',\n",
       " 'Coll-1770',\n",
       " 'Coll-1761',\n",
       " 'Coll-1762',\n",
       " 'Coll-1764',\n",
       " 'Coll-1773',\n",
       " 'Coll-1765',\n",
       " 'Coll-1766',\n",
       " 'Coll-1763',\n",
       " 'Coll-1771',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " 'Coll-1775',\n",
       " '',\n",
       " 'Coll-296',\n",
       " 'ORMS',\n",
       " '',\n",
       " 'Coll-1783',\n",
       " '',\n",
       " 'Coll-1786',\n",
       " 'Coll-1784',\n",
       " 'Coll-1787',\n",
       " 'EUA CA1',\n",
       " 'Coll-1788',\n",
       " 'Coll-1789',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " 'Coll-1790',\n",
       " 'Coll-1791',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " 'Coll-1792',\n",
       " 'Coll-1615',\n",
       " 'Coll-1151',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " 'Coll-1794',\n",
       " 'Coll-1795',\n",
       " 'Coll-1797',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " 'Coll-1798',\n",
       " 'Coll-1799',\n",
       " 'Coll-1800',\n",
       " 'Coll-1802',\n",
       " 'Coll-1803',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " ...]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(df[\"eadid\"])  # Some of these are empty strings!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1081\n",
      "['Coll-1064', 'Coll-31', 'Coll-51', 'Coll-204', 'Coll-206', 'Coll-205', 'Coll-1443', 'Coll-1444', 'Coll-1391', 'Coll-1371']\n"
     ]
    }
   ],
   "source": [
    "indeces = []\n",
    "for ui_list in ui:\n",
    "    indeces += [ui_list[0]]\n",
    "print(len(indeces))\n",
    "print(indeces[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# def flattenTwoDimensionalList(two_d_list):\n",
    "#     flattened = []\n",
    "#     for listoflists in two_d_list:\n",
    "#         for unit in listoflists:\n",
    "#             flattened += [unit]\n",
    "#     return flattened"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# titles = flattenTwoDimensionalList(ut)\n",
    "# # print(titles[0:30])\n",
    "# identifiers = flattenTwoDimensionalList(ui)\n",
    "# dates = flattenTwoDimensionalList(ud)\n",
    "# geogs = flattenTwoDimensionalList(gn)\n",
    "# lang = flattenTwoDimensionalList(lm)\n",
    "# scopecont = flattenTwoDimensionalList(sc)\n",
    "# bioghist = flattenTwoDimensionalList(bh)\n",
    "# procinfo = flattenTwoDimensionalList(pi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# print(len(titles))\n",
    "# print(len(identifiers))\n",
    "# print(len(dates))\n",
    "# print(len(geogs))\n",
    "# print(len(lang))\n",
    "# print(len(scopecont))\n",
    "# print(len(bioghist))\n",
    "# print(len(procinfo))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def writeListsToFilesPerFonds(indeces, titles, scopeconts, bioghists, procinfo):\n",
    "    maxI = len(indeces)\n",
    "    i = 0\n",
    "    while i < maxI:\n",
    "        filename = (indeces[i]).strip()\n",
    "        filename = filename.replace(\" \", \"_\")\n",
    "        filename = filename.replace(\"/\", \"_\")\n",
    "        filepath = \"descriptions_by_fonds/\"+filename+\".txt\"\n",
    "        with open(filepath, 'w') as f:\n",
    "            f.write(\"Identifier: \")\n",
    "            f.write(filename + \"\\n\")\n",
    "            for t in titles[i]:\n",
    "                t = t.strip()\n",
    "                f.write(\"\\nTitle:\\n\")\n",
    "                f.write(t + \"\\n\")\n",
    "            for s in scopeconts[i]:\n",
    "                s = s.strip()\n",
    "                f.write(\"\\nScope and Contents:\\n\")\n",
    "                f.write(s + \"\\n\")\n",
    "            for b in bioghists[i]:\n",
    "                b = b.strip()\n",
    "                f.write(\"\\nBiographical / Historical:\\n\")\n",
    "                f.write(b + \"\\n\")\n",
    "            for p in procinfo[i]:\n",
    "                p = p.strip()\n",
    "                f.write(\"\\nProcessing Information:\\n\")\n",
    "                f.write(p + \"\\n\")\n",
    "        f.close()\n",
    "        i += 1\n",
    "    return str(maxI) + \" files written\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1081 files written'"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "writeListsToFilesPerFonds(indeces, ut, unique_sc, unique_bh, unique_pi)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"preparing\"></a>\n",
    "## III. Preparing\n",
    "Prepare the files for annotation, ensuring ease in reading and splitting any excessively long files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import string\n",
    "import re\n",
    "import csv\n",
    "\n",
    "# Libraries for Natural Language Processing\n",
    "import nltk\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.tokenize import sent_tokenize\n",
    "from nltk.text import Text\n",
    "# nltk.download('punkt')\n",
    "# from nltk.probability import FreqDist\n",
    "# nltk.download('stopwords')\n",
    "# from nltk.corpus import stopwords\n",
    "from nltk.corpus import PlaintextCorpusReader\n",
    "# nltk.download('averaged_perceptron_tagger')\n",
    "# from nltk.tag import pos_tag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "directory = 'descriptions_by_fonds/'\n",
    "files = PlaintextCorpusReader(directory, '.+')\n",
    "tokens = files.words()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Identifier', ':', 'Title', ':', 'Papers', 'of', 'Professor', 'Sir', 'Kenneth', 'Murray', 'Title', ':', 'Awards', 'and', 'honours', 'Title', ':', 'Bronze', 'medal', 'from']\n"
     ]
    }
   ],
   "source": [
    "print(tokens[:20])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['.txt', 'AA4.txt', 'AA5.txt', 'AA6.txt', 'AA7.txt', 'BAI.txt', 'Coll-100.txt', 'Coll-1000.txt', 'Coll-1001.txt', 'Coll-1004.txt']\n"
     ]
    }
   ],
   "source": [
    "token_totals = []\n",
    "filenames = files.fileids()\n",
    "for f in filenames:\n",
    "        token_totals += [len(files.words(f))]\n",
    "file_lengths = dict(zip(filenames,token_totals))\n",
    "print(filenames[0:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{8, 9, 14, 2063, 15, 24595, 4115, 2068, 19, 23, 21, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 12333, 48, 47, 50, 51, 10290, 8242, 54, 55, 56, 24632, 52, 59, 57, 61, 58, 63, 64, 65, 66, 67, 68, 60, 70, 71, 72, 73, 74, 75, 8269, 78, 79, 77, 80, 82, 83, 81, 85, 86, 89, 91, 95, 97, 99, 100, 103, 104, 105, 106, 107, 108, 109, 110, 114, 116, 118, 119, 120, 121, 24, 124, 125, 126, 127, 128, 129, 131, 2180, 133, 134, 136, 137, 138, 139, 140, 142, 143, 144, 145, 147, 148, 149, 150, 151, 153, 154, 156, 157, 158, 159, 161, 163, 164, 45221, 166, 167, 168, 169, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 181, 182, 183, 2223, 184, 186, 187, 185, 190, 192, 196, 198, 199, 200, 202, 203, 204, 205, 207, 208, 209, 210, 211, 212, 213, 215, 216, 217, 218, 219, 222, 223, 224, 225, 226, 227, 230, 231, 233, 234, 235, 28908, 236, 237, 28911, 240, 241, 242, 239, 244, 245, 243, 247, 248, 249, 250, 251, 252, 253, 255, 256, 257, 258, 259, 260, 261, 262, 263, 264, 265, 266, 267, 268, 269, 53, 272, 273, 274, 275, 276, 277, 279, 280, 282, 283, 284, 286, 287, 288, 289, 290, 291, 292, 294, 295, 2343, 297, 299, 300, 301, 302, 303, 304, 305, 307, 308, 309, 311, 312, 313, 314, 62, 316, 317, 318, 319, 321, 323, 324, 327, 328, 329, 330, 331, 332, 333, 336, 337, 338, 339, 12626, 341, 342, 343, 340, 344, 346, 347, 345, 349, 350, 351, 352, 355, 356, 357, 358, 359, 361, 362, 363, 364, 365, 366, 367, 369, 371, 372, 374, 375, 377, 379, 381, 383, 385, 386, 387, 388, 389, 390, 391, 392, 393, 394, 396, 397, 399, 12689, 402, 403, 405, 406, 407, 409, 410, 411, 413, 415, 417, 419, 420, 421, 423, 427, 428, 429, 430, 431, 432, 433, 434, 435, 437, 438, 439, 440, 441, 442, 444, 446, 448, 449, 450, 4547, 456, 458, 462, 464, 465, 467, 470, 471, 472, 473, 474, 475, 476, 477, 478, 480, 486, 10728, 490, 491, 492, 493, 494, 495, 497, 498, 499, 500, 502, 503, 505, 507, 508, 510, 512, 513, 8706, 516, 389638, 519, 521, 523, 524, 525, 526, 527, 530, 531, 533, 536, 542, 543, 546, 547, 548, 554, 555, 557, 558, 560, 563, 567, 568, 569, 43579, 572, 574, 576, 578, 583, 584, 585, 608842, 587, 586, 590, 593, 595, 598, 600, 605, 607, 80479, 609, 613, 614, 618, 619, 624, 628, 629, 634, 635, 636, 637, 642, 643, 648, 651, 653, 654, 656, 658, 659, 660, 661, 666, 671, 675, 676, 677, 678, 680, 681, 682, 684, 689, 690, 8883, 696, 698, 146116, 709, 712, 713, 6859, 716, 724, 725, 733, 13027, 740, 742, 744, 756, 759, 770, 2820, 774, 779, 780, 787, 6934, 803, 17199, 815, 821, 826, 828, 832, 833, 835, 837, 838, 839, 851, 859, 861, 9059, 870, 876, 877, 4980, 889, 2942, 895, 35716, 7051, 916, 918, 926, 927, 2978, 930, 939, 947, 964, 11226, 3042, 1000, 1006, 1008, 1010, 1022, 1035, 1040, 1041, 1054, 7198, 1059, 3110, 1064, 1066, 1067, 1072, 3122, 1076, 3137, 1092, 23639, 1112, 11359, 3175, 1131, 3200, 1153, 1156, 1168, 1175, 1180, 1183, 1186, 1190, 1191, 1196, 1209, 11451, 1223, 1242, 3302, 1303, 1309, 5417, 1341, 3415, 1367, 1393, 1408, 3462, 1415, 1482, 1485, 1488, 1501, 7648, 1505, 1519, 1527, 120325, 3594, 1559, 97822, 1603, 1605, 28230, 1632, 20066, 13930, 1654, 212647, 32424, 1706, 1721, 7875, 32480, 3829, 1786, 16139, 5966, 1947, 63458}\n"
     ]
    }
   ],
   "source": [
    "token_totals.sort\n",
    "print(set(token_totals))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "826"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "file_lengths[\"Coll-1250.txt\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "too_long = []\n",
    "for key,value in file_lengths.items():\n",
    "    if value > 1000:\n",
    "        too_long += [key]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['BAI.txt', 'Coll-1022.txt', 'Coll-1036.txt', 'Coll-1052.txt', 'Coll-1057.txt', 'Coll-1059.txt', 'Coll-1060.txt', 'Coll-1061.txt', 'Coll-1062.txt', 'Coll-1064.txt', 'Coll-1066.txt', 'Coll-1142.txt', 'Coll-1146.txt', 'Coll-1156.txt', 'Coll-1162.txt', 'Coll-1167.txt', 'Coll-1242.txt', 'Coll-1243.txt', 'Coll-1247.txt', 'Coll-1255.txt', 'Coll-1257.txt', 'Coll-1260.txt', 'Coll-1266.txt', 'Coll-1294.txt', 'Coll-13.txt', 'Coll-1310.txt', 'Coll-1320.txt', 'Coll-1329.txt', 'Coll-1357.txt', 'Coll-1362.txt', 'Coll-1363.txt', 'Coll-1364.txt', 'Coll-1373.txt', 'Coll-1383.txt', 'Coll-1385.txt', 'Coll-14.txt', 'Coll-1434.txt', 'Coll-1443.txt', 'Coll-146.txt', 'Coll-1461.txt', 'Coll-1489.txt', 'Coll-1490.txt', 'Coll-1492.txt', 'Coll-1496.txt', 'Coll-1497.txt', 'Coll-1499.txt', 'Coll-1527.txt', 'Coll-1528.txt', 'Coll-1541.txt', 'Coll-1549.txt', 'Coll-1557.txt', 'Coll-1574.txt', 'Coll-1577.txt', 'Coll-1580.txt', 'Coll-1583.txt', 'Coll-1586.txt', 'Coll-1593.txt', 'Coll-16.txt', 'Coll-1613.txt', 'Coll-1623.txt', 'Coll-1638.txt', 'Coll-164.txt', 'Coll-1644.txt', 'Coll-1650.txt', 'Coll-1651.txt', 'Coll-1657.txt', 'Coll-1671.txt', 'Coll-1690.txt', 'Coll-17.txt', 'Coll-1700.txt', 'Coll-1711.txt', 'Coll-1715.txt', 'Coll-1725.txt', 'Coll-1728.txt', 'Coll-1749.txt', 'Coll-1756.txt', 'Coll-1758.txt', 'Coll-1798.txt', 'Coll-203.txt', 'Coll-204.txt', 'Coll-205.txt', 'Coll-206.txt', 'Coll-21.txt', 'Coll-27.txt', 'Coll-31.txt', 'Coll-36.txt', 'Coll-39.txt', 'Coll-41.txt', 'Coll-411.txt', 'Coll-42.txt', 'Coll-43.txt', 'Coll-51.txt', 'Coll-54.txt', 'Coll-64.txt', 'Coll-66.txt', 'Coll-67.txt', 'Coll-68.txt', 'Coll-70.txt', 'Coll-706.txt', 'Coll-71.txt', 'Coll-74.txt', 'Coll-85.txt', 'Coll-99.txt', 'ECA_TYP.txt', 'EUA_CA1.txt', 'EUA_CA14.txt', 'EUA_CA2.txt', 'EUA_GD31.txt', 'EUA_GD46.txt', 'EUA_GD58.txt', 'EUA_GD9.txt', 'EUA_IN1.txt', 'EUA_IN2.txt', 'EUA_IN20.txt', 'EUA_IN23.txt', 'GD2.txt', 'La.txt', 'Or_Ms.txt', 'PJM.txt']\n",
      "119\n"
     ]
    }
   ],
   "source": [
    "print(too_long)\n",
    "print(len(too_long))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "That's a lot of files to break up manually, so let's use Python to divide these large files into smaller files with a maximum of 100 lines each."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Code in this cell based on:\n",
    "# https://stackoverflow.com/questions/16289859/splitting-large-text-file-into-smaller-text-files-by-line-numbers-using-python\n",
    "def splitLargeFile(f, max_lines, old_dir, new_dir):\n",
    "    short = None\n",
    "    file_path = old_dir+f\n",
    "    with open(file_path) as long:\n",
    "        for line_no, line in enumerate(long):\n",
    "            if line_no % max_lines == 0:\n",
    "                if short:\n",
    "                    short.close()\n",
    "                f = f.replace(\".txt\",\"_\")\n",
    "                short_name = str(f)+'{}.txt'.format(line_no + max_lines)\n",
    "                new_path = new_dir+short_name\n",
    "                short = open(new_path, \"w\")\n",
    "            short.write(line)\n",
    "        if short:\n",
    "            short.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "for f in filenames:\n",
    "    splitLargeFile(f, 100, \"descriptions_by_fonds/\", \"descriptions_by_fonds_split/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total files to annotate: 3649\n"
     ]
    }
   ],
   "source": [
    "directory = 'descriptions_by_fonds_split/'\n",
    "files = PlaintextCorpusReader(directory, '.+')\n",
    "print(\"Total files to annotate:\",len(files.fileids()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"renaming\"></a>\n",
    "## IV. Renaming Pre-Annotated Files\n",
    "Renaming so the files are properly ordered"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "datadir = \"descriptions_by_fonds_split\"\n",
    "filenames = os.listdir(datadir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5\n"
     ]
    }
   ],
   "source": [
    "max_digits = 0\n",
    "for f in filenames:\n",
    "    fend = re.findall(\"\\d+\\.ann|\\d+\\.txt\",f)\n",
    "    if fend:\n",
    "        fdigits = len(re.findall(\"\\d\",fend[0])) \n",
    "        if fdigits > max_digits:\n",
    "            max_digits = fdigits\n",
    "print(max_digits)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pad file names with zeros so all are 5 digits long\n",
    "for f in filenames:\n",
    "    oldpath = os.path.join(datadir,f)\n",
    "    end_list = re.findall(\"\\d+\\.ann|\\d+\\.txt\",f)\n",
    "    if len(end_list) > 0:\n",
    "        start = f.replace(end_list[0],\"\")\n",
    "        digits = len(re.findall(\"\\d\",end_list[0]))\n",
    "        new_f = start + \"0\" * (max_digits - digits) + end_list[0]\n",
    "        newpath = os.path.join(datadir,new_f)\n",
    "        os.rename(oldpath, newpath)\n",
    "        \n",
    "# Note: code in this cell based on: https://stackoverflow.com/questions/2491222/how-to-rename-a-file-using-python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Put files in subfolders based on fonds (collection) identifier\n",
    "# filenames = os.listdir(datadir)\n",
    "# for f in filenames:\n",
    "#     oldpath = os.path.join(datadir,f)\n",
    "#     end_list = re.findall(\"\\d+\\.ann|\\d+\\.txt\",f)\n",
    "#     if len(end_list) > 0:\n",
    "#         identifier = f.replace(end_list[0],\"\")\n",
    "#         new_dir = os.path.join(datadir,identifier)\n",
    "#         try:\n",
    "#             os.makedirs(new_dir)\n",
    "#         except FileExistsError:\n",
    "#             # directory already exists\n",
    "#             pass\n",
    "#         newpath = os.path.join(new_dir,f)\n",
    "#         os.rename(oldpath, newpath)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"splitting\"></a>\n",
    "## V. Splitting Files Among Annotators\n",
    "* Total annotators: 5\n",
    "    * A1 and A2 to annotate with Person Name and Linguistic labels\n",
    "    * A3 and A4 to annotate with Contextual labels\n",
    "* Inter-annotator agreement (IAA) will be evaluated for:\n",
    "    * A1 and A2\n",
    "    * Me and A1\n",
    "    * Me and A2\n",
    "    * A3 and A4\n",
    "    * Me and A3\n",
    "    * Me and A4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Estimated files each annotator will label: 720\n",
      "Estimated files both pairs of annotators will label in total: 1440\n"
     ]
    }
   ],
   "source": [
    "# My pilot with finalized instructions begun 16:05 and ended at 16:35, many of the 15 files I \n",
    "# annotated were short on description, so let's estimate an average of 10 file in an hour, to be safe\n",
    "hired_hours = 9*8  # each annotator working 9 hours per week for 8 weeks\n",
    "est_files_annotated = hired_hours * 10\n",
    "print(\"Estimated files each annotator will label:\", est_files_annotated)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Allow 10% overlap for each pair of annotators, totaling 72 files\n",
      "Estimated files both pairs of annotators will label in total: 1368\n"
     ]
    }
   ],
   "source": [
    "print(\"Allow 10% overlap for each pair of annotators, totaling\", str(int(720*0.1)), \"files\")\n",
    "print(\"Estimated files both pairs of annotators will label in total:\", (est_files_annotated * 2) - int(720*0.1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from shutil import copyfile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7298\n",
      "AA4_00100.ann\n",
      "AA4_00100.txt\n",
      "AA5_00100.ann\n",
      "AA5_00100.txt\n",
      "True\n"
     ]
    }
   ],
   "source": [
    "directory = \"descriptions_by_fonds_split_with_ann/descriptions_by_fonds_split_with_ann\"\n",
    "descs_split = list(os.listdir(directory))\n",
    "descs_split.sort()\n",
    "descs_split.pop(0)\n",
    "print(len(descs_split))\n",
    "print(descs_split[0])\n",
    "print(descs_split[1])\n",
    "print(descs_split[2])\n",
    "print(descs_split[3])\n",
    "print(\".txt\" in descs_split[1])\n",
    "# print(descs_split)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "146\n",
      "2848\n"
     ]
    }
   ],
   "source": [
    "print(73*2)\n",
    "print(1461+1460-73)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Select approximately 10% of the total number of files for the hired annotators, and select approximately 10% of that number of files to be doubly annotated by the hired annotators.\n",
    "* 730 txt files per annotator (including ann files, 1460 files total)\n",
    "* First 73 txt files annotated by everyone"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1460\n",
      "1533\n",
      "['Coll-1434_14300.ann', 'Coll-1434_14300.txt', 'Coll-1434_14400.ann', 'Coll-1434_14400.txt', 'Coll-1434_14500.ann', 'Coll-1434_14500.txt', 'Coll-1434_14600.ann', 'Coll-1434_14600.txt', 'Coll-1434_14700.ann', 'Coll-1434_14700.txt']\n",
      "['Coll-1584_00100.ann', 'Coll-1584_00100.txt', 'Coll-1585_00100.ann', 'Coll-1585_00100.txt', 'Coll-1586_00100.ann', 'Coll-1586_00100.txt', 'Coll-1586_00200.ann', 'Coll-1586_00200.txt', 'Coll-1586_00300.ann', 'Coll-1586_00300.txt']\n"
     ]
    }
   ],
   "source": [
    "fonds1 = descs_split[0:1460]                           # 730 * 2 to account for .ann files\n",
    "fonds2 = descs_split[0:146] + descs_split[1461:2848]   # only first 76 txt files (146 with ann files) should overlap\n",
    "        \n",
    "print(len(fonds1))\n",
    "print(len(fonds2))\n",
    "print(fonds1[-10:])\n",
    "print(fonds2[-10:])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Copy the select files of metadata descriptions into folders for each annotator."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "for f in fonds1:\n",
    "    oldpath = os.path.join(directory,f)\n",
    "    newpath1 = os.path.join(\"ann1\",f)  # paired with ann2\n",
    "    newpath2 = os.path.join(\"ann3\",f)  # paired with ann4\n",
    "    copyfile(oldpath, newpath1)\n",
    "    copyfile(oldpath, newpath2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "for f in fonds2:\n",
    "    oldpath = os.path.join(directory,f)\n",
    "    newpath3 = os.path.join(\"ann2\",f)  # paired with ann1\n",
    "    newpath4 = os.path.join(\"ann4\",f)  # paired with ann3\n",
    "    copyfile(oldpath, newpath3)\n",
    "    copyfile(oldpath, newpath4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "def countWordsInDirectory(directory):\n",
    "    files = PlaintextCorpusReader(directory, '.+\\.txt')\n",
    "    tokens = files.words()\n",
    "    print(str(directory)+\": \" + str(len(tokens)))\n",
    "    return\n",
    "\n",
    "pair1_words = countWordsInDirectory(\"ann1/\")                                   # 486880\n",
    "pair2_words = countWordsInDirectory(\"ann3/\")                                   # 595018\n",
    "total_words = countWordsInDirectory(\"descriptions_by_fonds_split_with_ann\")    # 2754044"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Percentage of dataset annotated by annotator pair 1: 17.678729896835343\n"
     ]
    }
   ],
   "source": [
    "print(\"Percentage of dataset annotated by annotator pair 1:\",(pair1_words/total_words)*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Percentage of dataset annotated by annotator pair 2: 21.60524668451194\n"
     ]
    }
   ],
   "source": [
    "print(\"Percentage of dataset annotated by annotator pair 2:\",(pair2_words/total_words)*100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If each pair of annotators annotates about half the total files allocated to them, in total, about 10% of my entire dataset will be doubly annotated (because I'm labeling all files with all categories)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "89273\n"
     ]
    }
   ],
   "source": [
    "overlap = descs_split[0:146]\n",
    "files = PlaintextCorpusReader(directory, '.+\\.txt')\n",
    "fileids = files.fileids()\n",
    "overlap_token_count = 0\n",
    "for f in fileids:\n",
    "    if f in overlap:\n",
    "        overlap_token_count += len(files.words(f))\n",
    "print(overlap_token_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.2415241005590323\n"
     ]
    }
   ],
   "source": [
    "total_tokens = 2754044\n",
    "print((overlap_token_count/total_tokens)*100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The files that EVERYONE annotates represent about 3% of the total dataset, meaning about 3% of the data will be triply annotated."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
